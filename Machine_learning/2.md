## 神经网络
- 解决非线性分类问题
- 与线性回归和逻辑回归同级
- 激活函数 -- 非线性函数
- 模型参数 -- 权重
- x0为偏执单元，等于1
- 单个神经元：![Alt text](image-25.png)
- 神经网络（一组神经元）：![Alt text](image-26.png)
- 参数：a-激活项，theta-权重矩阵
- ![Alt text](image-27.png)
- 二元分类：![Alt text](image-29.png)
- 多分类：![Alt text](image-28.png)
- 代价函数：![Alt text](image-31.png)
- 反向传播算法：g是sigmoid激活函数，第四层误差是实际值和计算值的差，第二三层误差是对损失函数求偏导后的化简：![Alt text](image-32.png)![Alt text](image-33.png)/54
  - 反向传播可能会出现一些意想不到的bug，因此进行梯度检验：![Alt text](image-34.png)
  - 将梯度检验计算出来的梯度gradApprox和反向传播计算出来的梯度DVec进行比较，通过调整DVec的计算方法保证DVec和gradApprox比较接近
  - 确定反向梯度传播的正确性后，关掉梯度检验（计算量太大），用满足了刚刚梯度检验的后向传播代码进行神经网络的学习
- 权重矩阵进行随机初始化（若是全部初始化为0则会使梯度下降迭代失去意义，所有的值都相等 -- 对称权重问题）![Alt text](image-36.png)即生成服从-epsilon到epsilon均匀分布的随机值
- 步骤：![Alt text](image-37.png)
  - 1. 构建神经网络，随机初始化权重（通常初始化为很小的值，接近于0）
  - 2. 向前传播，计算出y
  - 3. 计算代价函数
  - 4. 反向传播，计算代价函数偏导数
  - 5. 梯度检验，与反向传播数值进行比较
  - 6. 关掉梯度检测，进行梯度下降（或其他高级优化算法）
- 调参方法：![Alt text](image-38.png)
- 机器学习诊断法 -- 用于评价算法，并算法进行有效改进
  - 把数据分为训练集、验证集、测试集/60
